<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Chapter 02 | Mostafa Touny</title>
<meta name=keywords content><meta name=description content="$\newcommand{\nfrac}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}$
Exercises
Ex. 1
Part I
Take $m = n-1$, and let $R$ be the algorithm&rsquo;s output. $R = 0$ if and only if $RNG()$ returned $0$ or $n-1$. So $Pr[R = 0] = 2/n$ and $Pr[R = i] = 1/n$ for $i \neq 0$.
Part II
Define $k = \lfloor n/m \rfloor$, So $k$ is the greatest integer such that $mk \leq n$. Define $r = n \mod mk$, so $n = mk + r$ where $0 \leq r < m$."><meta name=author content><link rel=canonical href=https://mostafatouny.github.io/harvey-rand-post/pset02/><link crossorigin=anonymous href=/assets/css/stylesheet.e6ee52f0fc7c2e3dbd78858fc1b3e06fb86a3c6ee38d351342e06e23a24d02d6.css integrity="sha256-5u5S8Px8Lj29eIWPwbPgb7hqPG7jjTUTQuBuI6JNAtY=" rel="preload stylesheet" as=style><link rel=icon href=https://mostafatouny.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://mostafatouny.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mostafatouny.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://mostafatouny.github.io/apple-touch-icon.png><link rel=mask-icon href=https://mostafatouny.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://mostafatouny.github.io/harvey-rand-post/pset02/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Chapter 02"><meta property="og:description" content="$\newcommand{\nfrac}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}$
Exercises
Ex. 1
Part I
Take $m = n-1$, and let $R$ be the algorithm&rsquo;s output. $R = 0$ if and only if $RNG()$ returned $0$ or $n-1$. So $Pr[R = 0] = 2/n$ and $Pr[R = i] = 1/n$ for $i \neq 0$.
Part II
Define $k = \lfloor n/m \rfloor$, So $k$ is the greatest integer such that $mk \leq n$. Define $r = n \mod mk$, so $n = mk + r$ where $0 \leq r < m$."><meta property="og:type" content="article"><meta property="og:url" content="https://mostafatouny.github.io/harvey-rand-post/pset02/"><meta property="article:section" content="harvey-rand-post"><meta property="article:published_time" content="2023-12-11T00:00:00+00:00"><meta property="article:modified_time" content="2023-12-11T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Chapter 02"><meta name=twitter:description content="$\newcommand{\nfrac}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}$
Exercises
Ex. 1
Part I
Take $m = n-1$, and let $R$ be the algorithm&rsquo;s output. $R = 0$ if and only if $RNG()$ returned $0$ or $n-1$. So $Pr[R = 0] = 2/n$ and $Pr[R = i] = 1/n$ for $i \neq 0$.
Part II
Define $k = \lfloor n/m \rfloor$, So $k$ is the greatest integer such that $mk \leq n$. Define $r = n \mod mk$, so $n = mk + r$ where $0 \leq r < m$."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Harvey's Randomized Algorithms","item":"https://mostafatouny.github.io/harvey-rand-post/"},{"@type":"ListItem","position":2,"name":"Chapter 02","item":"https://mostafatouny.github.io/harvey-rand-post/pset02/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Chapter 02","name":"Chapter 02","description":"$\\newcommand{\\nfrac}[2]{\\frac{\\displaystyle{#1}}{\\displaystyle{#2}}}$\nExercises Ex. 1 Part I Take $m = n-1$, and let $R$ be the algorithm\u0026rsquo;s output. $R = 0$ if and only if $RNG()$ returned $0$ or $n-1$. So $Pr[R = 0] = 2/n$ and $Pr[R = i] = 1/n$ for $i \\neq 0$.\nPart II Define $k = \\lfloor n/m \\rfloor$, So $k$ is the greatest integer such that $mk \\leq n$. Define $r = n \\mod mk$, so $n = mk + r$ where $0 \\leq r \u003c m$.\n","keywords":[],"articleBody":"$\\newcommand{\\nfrac}[2]{\\frac{\\displaystyle{#1}}{\\displaystyle{#2}}}$\nExercises Ex. 1 Part I Take $m = n-1$, and let $R$ be the algorithm’s output. $R = 0$ if and only if $RNG()$ returned $0$ or $n-1$. So $Pr[R = 0] = 2/n$ and $Pr[R = i] = 1/n$ for $i \\neq 0$.\nPart II Define $k = \\lfloor n/m \\rfloor$, So $k$ is the greatest integer such that $mk \\leq n$. Define $r = n \\mod mk$, so $n = mk + r$ where $0 \\leq r \u003c m$.\ndef goodSampler(m) k = floor( n/m ) do r = RNG() while r \u003e= mk return r mod m Uniformity. Assume the algorithm terminates. So we are given $r \u003c mk$ and we want to prove $Pr[r \\mod m = i \\mid r \u003c mk] = \\nfrac{1}{m}$ for $i \\in [m]$. Observe \\begin{aligned} Pr[r \\mod m = i \\mid r \u003c mk] \u0026= \\nfrac{Pr[r \\mod m = i \\cap r \u003c mk]}{Pr[r \u003c mk]} \\\\ \u0026= \\nfrac{k/n}{mk/n} = \\nfrac{k}{n} \\cdot \\nfrac{n}{mk} = \\nfrac{1}{m} \\end{aligned} Recall by uniformity the probability is basically the number of outcomes satisfying the event over all possible outcomes. Clearly the $k$ outcomes of $r$ yielding $i$ by the algorithm are $(0)m + i, (1)m + i, (2)m + i, \\dots, (k-1)m + (i)$.\nTime Complexity. For an iteration of do-while, probability of termination is $mk/n$. So in expectation it takes $n/mk$ trials until it terminates. It follows $$ 1 \\leq \\nfrac{n}{mk} = 1 + \\nfrac{r}{mk} \u003c 1 + \\nfrac{m}{mk} = 1 + \\nfrac{1}{k} \\leq 2. $$ Concluding its time is $\\mathcal{O}(1)$.\nEx. 2 Distribution. see ex-2.2 notebook.\nThe distribution of the given psuedo-code seems uniform.\nThe distribution but with modifying the probability to be hardcoded p = 0.7 rather than p = ContinuousUniform() in line 2, seems normal.\nRecall we know in expectation we will get 7 1-bits out of 10 by linearity of random variables.\nRemark. $X = \\sum X_i^n$ is equivalent to number of $1$s tossed.\nLemma. Probability of tossing $k$ $1s$.\nFor some fixed probability of getting 1 $p$, and number of coin tosses $n$, The probability of drawing $k$ $1s$ is $Pr[X = k] = (p)^k (1-p)^{n-k} \\dbinom{n}{k}$, Since the distribution of coin tossing is binomial.\nEx. 3 Part I Algorithm.\n# input: Probabilities P[i] # output: category sampled def categoricalSampler( P[1..k] ) # initially the universe is all probabilities totalProb = sum( P[1..k] ) # for each ith probability for i in 1..k # compute P[i] probability in ratio to the universe i_prob_uni = (1/totalProb) * P[i] # return i by that probability if biasedBit( i_prob_uni ) return i # remove P[i] from the universe totalProb -= P[i] Correctness. Computing a probability out of a subset of probabilities.\nWe want to compute a probability but in ratio to some subset of probabilities.\nFor example if $Pr[X = i] = 1/4$ for $i \\in \\{ 1,2,3,4 \\}$, But we are given $X \\not\\in \\{1, 2\\}$. Then $Pr[X = 3 \\mid X \\not\\in \\{1,2\\}] = \\nfrac{Pr[X = 3 \\cap X \\not\\in \\{1,2\\}]}{Pr[X \\not\\in \\{1,2\\}]} = \\nfrac{1/4}{1/2} = 2 \\cdot \\nfrac{1}{4}$.\nGenerally we want to find $x$ where, For sum $S$ of some subset of probabilities, $\\nfrac{Pr[X = i]}{S} = \\nfrac{x}{1}$, so $x = \\nfrac{1}{S} \\cdot Pr[X=i]$.\nCorrectness. categoricalSampler returns a category.\nIf the algorithm reached iteration $k$, i_prob_uni would be $1$ so biasedBit surely fires.\nTime Complexity. Clearly $\\mathcal{O}(k)$.\nPart II Algorithm\n# input: probabilities P[i] # output: cumulative sum of probabilities S[i] def cumulativeSum( P[1..k] ) # S[i] is sum up to P[i] S = [] sum = 0 # compute \u0026 append S[i] for i in 1..k # cumulative sum up to P[i] sum += P[i] # append as S[i] S.append( sum ) return S # input: probabilities P[i], and cumulative probabilities S[i] # output: sampled category i def recursiveSampler( P[l..r], S[l..r] ) # base case. universe is one category so its probability is 1 if l = r return l # center index mid = floor( (r-l)/2 ) # total probability of P[l..r] totalProb = S[r] - S[l] + P[l] # probability of cumulative half of P in ratio to the universe prob_uni = (1/totalProb) * S[mid] # toss a coin by cumulative probability of half of P if biasedBit( prob_uni ) # if True then the sample is restricted to them return recursiveSampler( P[l..mid], S[l..mid] ) else # if False then the sample is not any of them return recursiveSampler( P[mid+1..r], S[mid+1..r] ) # input: probabilities P[i] # output: sampled category i def categoricalSampler2( P[1..k] ) # preprocessing, computing cumulative sum of probabilities S = cumulativeSum( P[1..k] ) # sample a category return recursiveSampler( P, S ) Correctness. recursiveSampler won’t ever reach array P of size zero.\nThat can only happen if either mid = r or mid = l, but then S[mid] = 1 or S[mid] = 0 respectively. Contradiction.\nCorrectness. The algorithm samples category $i$ with probability $P[i]$.\nThe remarks from Part I holds here. We show a more formal proof.\nLet $X = z$ denote the event of sampling category $z$. Let $j_1, j_2, \\dots, j_{k-1}$ be the remaining categories. Then $Pr[X = z] = Pr[X \\neq j_1 \\cap X \\neq j_2 \\cap \\dots \\cap X \\neq j_{k-1}]$. Partition $j$s on subsets of outcomes $O_1, O_2, \\dots, O_{\\log k}$. \\begin{aligned} Pr[X = z] \u0026= Pr[X \\notin O_1 \\cap X \\notin O_2 \\cap \\dots \\cap X \\notin O_{\\log k}] \\\\ \u0026= Pr[X \\notin O_1 \\mid X \\notin O_2 \\cap \\dots \\cap X \\notin O_{\\log k}] \\\\ \u0026\\cdot Pr[X \\notin O_2 \\mid X \\notin O_{3} \\dots \\cap X \\notin O_{\\log k}] \\cdot .. \\cdot Pr[X \\notin O_{\\log k}] \\end{aligned}\nLet $R$ be the algorithm’s output, and let $R_i$ correspond to biasedBit in iteration $i$. Clearly $Pr[R \\in \\{l, l+1, \\dots, mid\\}] = Pr[R_i = True]$ and $Pr[R \\in \\{mid+1, mid+2, \\dots, r\\}] = Pr[R_i = False]$. The algorithm samples $z$ if and only if $R_1 = x_1 \\cap R_2 = x_2 \\cap \\dots \\cap R_{\\log k} = x_{\\log k}$ corresponding to $x_i = True$ if $z \\notin \\{mid+1, \\dots, r\\} = O_i$. In other words the algorithm satisfies the definition of $Pr[X = z]$.\nTime Complexity. Clearly cumulativeSum takes $\\mathcal{O}(k)$ and recursiveSampler takes $\\mathcal{O}(\\log k)$.\nEx. 4 Idea. See the following sketch for an intuition.\nCompute cumulative sums $q_i$. Construct k intervals, each of size $1/k$. If some $q_i$ is sandwiched in some interval, separate that interval to two pieces. Accordingly label pieces which $p_i$ they belong to. Sample a UniformLBitInteger to select a uniformly random interval out of those k intervals. If it is separated, Toss a coin by BiasedBit to decide a piece. Output the piece’s label. Algorithm.\n# input: probabilities P[i] # output: cumulative sum of probabilities S[i] def cumulativeSum( P[1..k] ) S = [] sum = 0 for i in 1..k sum += P[i] S.append(sum) return S # input: integer k # output: k-intervals of size 1/k each def kIntervalsConstruction( k ) # start, end, and separation points, decides a pair of intervals # end - start = 1/k intervals = [ [st, end, sep, label] ] # construct the k intervals for i in 1..k # length of interval is 1/k intervals.append( [ (i-1)/k, i/k, NULL, NULL ] ) return intervals # input: 2d-array of k-intervals, and the cumulative sum S # output: None. It modifies the 2d-array to be filled with separators and labels def sepPointsFromArray( Inter[1..k, 4], S[1..k] ) # pointer for S S_poi = 1 # for each kth interval for i in 1..k # if S[S_poi] is contained in the kth interval if Inter[i][st] \u003c= S[ S_poi ] \u003c= Inter[i][en] # set S[S_poi] as the separator Inter[i][sep] = S[ S_poi ] # consider next index S_poi += 1 # otherwise, leave the separator with NULL # in either cases cache S_poi # latter case. whole interval is labeled by S_poi # former case. first piece is labeled by S_poi and # second piece is labeled by S_poi+1 Inter[i][label] = S_poi # input: k-probabilities P[i] # output: k intervals, each of size 1/k, possibly separated to have pairs def intervalToPieces( P[1..k] ) # S[i] is cumulative sum up to P[i] S = cumulativeSum( P ) # construct k-intervals of size 1/k each intervals = kIntervalsConstruction( k ) # in-place fill \"sep\" and \"label\" cells in intervals sepPointsFromArray(intervals, S) return intervals # input: Probabilities P[i] # output: sampled category i def sample( P[1..k] ) # preprocessing is not needed to be called for every sample call intervals = intervalToPieces( P ) # uniform random index of intervals randIndex = uniformLBitInteger(lg k) # uniform random interval from intervals randInterval = intervals[ randIndex ] # if it has no separator if randInterval[sep] = NULL # then it belongs to cached label return randInterval[label] else # it has a separator # compute proportion of separator in ratio to the interval of size 1/k prop = (randInterval[sep] - randInterval[st]) / (1/k) # toss a coin by a probability proportional to the separator if biasedBit(prop) # if it lands before the separator then we are in a piece labeled by \"cached label\" return randInterval[label] else # if it lands after the separator then we are in the piece next to one labeled by \"cached label\" return randInterval[label] + 1 Correctness. No probabilistic claim is outside what we proved and illustrated in previous exercises.\nTime Complexity. Preprocessing consumes $O(k)$, Since all its subroutines take $O(k)$ each. Sampling consumes $O(1)$ since both uniformLBitInteger and biasedBit consume $O(1)$.\nEx. 5 Postponed.\nEx. 6 Note. It feels weird we derived a solution better than the requested bound.\nAlgorithm\ndef uniformPrime(n) do # keep sampling uniform numbers in {1, .., 20n} rand = uniformRandom(20n) # as long as the sampled is not prime while not isPrime(rand) # only if we found a prime, we return it return rand Correctness. We used the technique of Rejection Sampling which guarantees the prime number output is uniform. The proof idea is very similar to our previous probability proofs.\nAnalysis. From Fact A.2.12 (page 226), There are at least $n/\\ln n$ primes in $P_n$. So the probability of a successful trial is at least $n/\\ln n$. Then the number of trials is at most $\\ln n/n$ in expectation by Fact A.3.20 (page 233). Observe $\\ln n / n \\leq \\log n / n$. Since we are given isPrime is $\\mathcal{O}(\\log^7 n)$, The whole algorithm uniformPrime takes at most $\\mathcal{O}(\\log^8 / n) \\subset \\mathcal{O}(\\log^{10} n)$.\nEx. 7 Part I The probability of sampling from $R$ is $\\nfrac{\\textit{disk-area}}{\\textit{square-area}} = \\nfrac{\\pi(1)^2}{2*2} \\approx \\nfrac{22}{7} \\cdot \\nfrac{1}{4} = \\nfrac{22}{28}$.\nIt follows the number of iterations is at most $\\nfrac{28}{22} = 1 + \\nfrac{3}{11} \\leq 2$.\nPart II Partially Solved.\nSeemingly we just need to compute volumes of both $S$ and $R$ but in $20th$ dimension, and follow exactly the same recipe of Part I.\n","wordCount":"1796","inLanguage":"en","datePublished":"2023-12-11T00:00:00Z","dateModified":"2023-12-11T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://mostafatouny.github.io/harvey-rand-post/pset02/"},"publisher":{"@type":"Organization","name":"Mostafa Touny","logo":{"@type":"ImageObject","url":"https://mostafatouny.github.io/favicon.ico"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["$$","$$"],["\\[","\\]"]],inlineMath:[["$","$"],["\\(","\\)"]]}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mostafatouny.github.io/ accesskey=h title="Mostafa Touny (Alt + H)">Mostafa Touny</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://mostafatouny.github.io/about title=About><span>About</span></a></li><li><a href=https://mostafatouny.github.io/post title=Blog><span>Blog</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Chapter 02</h1><div class=post-meta><span title='2023-12-11 00:00:00 +0000 UTC'>December 11, 2023</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#exercises aria-label=Exercises>Exercises</a><ul><li><a href=#ex.-1 aria-label="Ex. 1">Ex. 1</a><ul><li><a href=#part-i aria-label="Part I">Part I</a></li><li><a href=#part-ii aria-label="Part II">Part II</a></li></ul></li><li><a href=#ex.-2 aria-label="Ex. 2">Ex. 2</a></li><li><a href=#ex.-3 aria-label="Ex. 3">Ex. 3</a><ul><li><a href=#part-i-1 aria-label="Part I">Part I</a></li><li><a href=#part-ii-1 aria-label="Part II">Part II</a></li></ul></li><li><a href=#ex.-4 aria-label="Ex. 4">Ex. 4</a></li><li><a href=#ex.-5 aria-label="Ex. 5">Ex. 5</a></li><li><a href=#ex.-6 aria-label="Ex. 6">Ex. 6</a></li><li><a href=#ex.-7 aria-label="Ex. 7">Ex. 7</a><ul><li><a href=#part-i-2 aria-label="Part I">Part I</a></li><li><a href=#part-ii-2 aria-label="Part II">Part II</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><p>$\newcommand{\nfrac}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}$</p><h2 id=exercises class=unnumbered>Exercises<a hidden class=anchor aria-hidden=true href=#exercises>#</a></h2><h3 id=ex.-1 class=unnumbered>Ex. 1<a hidden class=anchor aria-hidden=true href=#ex.-1>#</a></h3><h4 id=part-i class=unnumbered>Part I<a hidden class=anchor aria-hidden=true href=#part-i>#</a></h4><p>Take $m = n-1$, and let $R$ be the algorithm&rsquo;s output. $R = 0$ if and only if $RNG()$ returned $0$ or $n-1$. So $Pr[R = 0] = 2/n$ and $Pr[R = i] = 1/n$ for $i \neq 0$.</p><h4 id=part-ii class=unnumbered>Part II<a hidden class=anchor aria-hidden=true href=#part-ii>#</a></h4><p>Define $k = \lfloor n/m \rfloor$, So $k$ is the greatest integer such that $mk \leq n$. Define $r = n \mod mk$, so $n = mk + r$ where $0 \leq r < m$.</p><pre tabindex=0><code>    def goodSampler(m)
      k = floor( n/m )

      do
        r = RNG()
      while r &gt;= mk

      return r mod m
</code></pre><p><strong>Uniformity</strong>. Assume the algorithm terminates. So we are given $r < mk$ and we want to prove $Pr[r \mod m = i \mid r < mk] = \nfrac{1}{m}$ for $i \in [m]$. Observe
\begin{aligned}
Pr[r \mod m = i \mid r &lt; mk] &= \nfrac{Pr[r \mod m = i \cap r &lt; mk]}{Pr[r &lt; mk]} \\
&= \nfrac{k/n}{mk/n} = \nfrac{k}{n} \cdot \nfrac{n}{mk} = \nfrac{1}{m}
\end{aligned}
Recall by uniformity the probability is basically the number of outcomes satisfying the event over all possible outcomes. Clearly the $k$ outcomes of $r$ yielding $i$ by the algorithm are $(0)m + i, (1)m + i, (2)m + i, \dots, (k-1)m + (i)$.</p><p><strong>Time Complexity</strong>. For an iteration of <code>do-while</code>, probability of termination is $mk/n$. So in expectation it takes $n/mk$ trials until it terminates. It follows</p>$$
1 \leq \nfrac{n}{mk} = 1 + \nfrac{r}{mk} < 1 + \nfrac{m}{mk} = 1 + \nfrac{1}{k} \leq 2.
$$<p>Concluding its time is $\mathcal{O}(1)$.</p><h3 id=ex.-2 class=unnumbered>Ex. 2<a hidden class=anchor aria-hidden=true href=#ex.-2>#</a></h3><p><strong>Distribution</strong>. see <em>ex-2.2</em> notebook.</p><p>The distribution of the given psuedo-code seems uniform.</p><p><img loading=lazy src=./ex-2.2_0.png alt=image></p><p>The distribution but with modifying the probability to be hardcoded <code>p = 0.7</code> rather than <code>p = ContinuousUniform()</code> in line 2, seems normal.</p><p><img loading=lazy src=./ex-2.2_1.png alt=image></p><p>Recall we know in expectation we will get 7 1-bits out of 10 by linearity of random variables.</p><p><strong>Remark</strong>. $X = \sum X_i^n$ is equivalent to number of $1$s tossed.</p><p><strong>Lemma</strong>. Probability of tossing $k$ $1s$.</p><p>For some fixed probability of getting 1 $p$, and number of coin tosses $n$, The probability of drawing $k$ $1s$ is $Pr[X = k] = (p)^k (1-p)^{n-k} \dbinom{n}{k}$, Since the distribution of coin tossing is binomial.</p><h3 id=ex.-3 class=unnumbered>Ex. 3<a hidden class=anchor aria-hidden=true href=#ex.-3>#</a></h3><h4 id=part-i-1 class=unnumbered>Part I<a hidden class=anchor aria-hidden=true href=#part-i-1>#</a></h4><p><strong>Algorithm.</strong></p><pre tabindex=0><code>    # input: Probabilities P[i]
    # output: category sampled
    def categoricalSampler( P[1..k] )

      # initially the universe is all probabilities
      totalProb = sum( P[1..k] )

      # for each ith probability
      for i in 1..k

        # compute P[i] probability in ratio to the universe
        i_prob_uni = (1/totalProb) * P[i]

        # return i by that probability
        if biasedBit( i_prob_uni )
          return i

        # remove P[i] from the universe
        totalProb -= P[i]
</code></pre><p><strong>Correctness.</strong> Computing a probability out of a subset of probabilities.</p><p>We want to compute a probability but in ratio to some subset of probabilities.</p><p>For example if $Pr[X = i] = 1/4$ for $i \in \{ 1,2,3,4 \}$, But we are given $X \not\in \{1, 2\}$. Then $Pr[X = 3 \mid X \not\in \{1,2\}] = \nfrac{Pr[X = 3 \cap X \not\in \{1,2\}]}{Pr[X \not\in \{1,2\}]} = \nfrac{1/4}{1/2} = 2 \cdot \nfrac{1}{4}$.</p><p>Generally we want to find $x$ where, For sum $S$ of some subset of probabilities, $\nfrac{Pr[X = i]}{S} = \nfrac{x}{1}$, so $x = \nfrac{1}{S} \cdot Pr[X=i]$.</p><p><strong>Correctness.</strong> <code>categoricalSampler</code> returns a category.</p><p>If the algorithm reached iteration $k$, <code>i_prob_uni</code> would be $1$ so <code>biasedBit</code> surely fires.</p><p><strong>Time Complexity.</strong> Clearly $\mathcal{O}(k)$.</p><h4 id=part-ii-1 class=unnumbered>Part II<a hidden class=anchor aria-hidden=true href=#part-ii-1>#</a></h4><p><strong>Algorithm</strong></p><pre tabindex=0><code>    # input: probabilities P[i]
    # output: cumulative sum of probabilities S[i]
    def cumulativeSum( P[1..k] )
        
        # S[i] is sum up to P[i]
        S = []

        sum = 0

        # compute &amp; append S[i]
        for i in 1..k
            
            # cumulative sum up to P[i]
            sum += P[i]
            
            # append as S[i]
            S.append( sum )

        return S

    # input: probabilities P[i], and cumulative probabilities S[i]
    # output: sampled category i
    def recursiveSampler( P[l..r], S[l..r] )
        # base case. universe is one category so its probability is 1
        if l = r
            return l

        # center index
        mid = floor( (r-l)/2 )

        # total probability of P[l..r]
        totalProb = S[r] - S[l] + P[l]

        # probability of cumulative half of P in ratio to the universe
        prob_uni = (1/totalProb) * S[mid]

        # toss a coin by cumulative probability of half of P
        if biasedBit( prob_uni )

            # if True then the sample is restricted to them
            return recursiveSampler( P[l..mid], S[l..mid] )
        else
            
            # if False then the sample is not any of them
            return recursiveSampler( P[mid+1..r], S[mid+1..r] )

    # input: probabilities P[i]
    # output: sampled category i
    def categoricalSampler2( P[1..k] )
        
        # preprocessing, computing cumulative sum of probabilities
        S = cumulativeSum( P[1..k] )

        # sample a category
        return recursiveSampler( P, S )
</code></pre><p><strong>Correctness.</strong> <code>recursiveSampler</code> won&rsquo;t ever reach array <code>P</code> of size zero.</p><p>That can only happen if either <code>mid = r</code> or <code>mid = l</code>, but then <code>S[mid] = 1</code> or <code>S[mid] = 0</code> respectively. Contradiction.</p><p><strong>Correctness.</strong> The algorithm samples category $i$ with probability $P[i]$.</p><p>The remarks from <em>Part I</em> holds here. We show a more formal proof.</p><p>Let $X = z$ denote the event of sampling category $z$. Let $j_1, j_2, \dots, j_{k-1}$ be the remaining categories. Then $Pr[X = z] = Pr[X \neq j_1 \cap X \neq j_2 \cap \dots \cap X \neq j_{k-1}]$. Partition $j$s on subsets of outcomes $O_1, O_2, \dots, O_{\log k}$.
\begin{aligned}
Pr[X = z] &= Pr[X \notin O_1 \cap X \notin O_2 \cap \dots \cap X \notin O_{\log k}] \\
&= Pr[X \notin O_1 \mid X \notin O_2 \cap \dots \cap X \notin O_{\log k}] \\ &\cdot Pr[X \notin O_2 \mid X \notin O_{3} \dots \cap X \notin O_{\log k}] \cdot .. \cdot Pr[X \notin O_{\log k}]
\end{aligned}</p><p>Let $R$ be the algorithm&rsquo;s output, and let $R_i$ correspond to <code>biasedBit</code> in iteration $i$. Clearly $Pr[R \in \{l, l+1, \dots, mid\}] = Pr[R_i = True]$ and $Pr[R \in \{mid+1, mid+2, \dots, r\}] = Pr[R_i = False]$. The algorithm samples $z$ if and only if $R_1 = x_1 \cap R_2 = x_2 \cap \dots \cap R_{\log k} = x_{\log k}$ corresponding to $x_i = True$ if $z \notin \{mid+1, \dots, r\} = O_i$. In other words the algorithm satisfies the definition of $Pr[X = z]$.</p><p><strong>Time Complexity</strong>. Clearly <code>cumulativeSum</code> takes $\mathcal{O}(k)$ and <code>recursiveSampler</code> takes $\mathcal{O}(\log k)$.</p><h3 id=ex.-4 class=unnumbered>Ex. 4<a hidden class=anchor aria-hidden=true href=#ex.-4>#</a></h3><p><strong>Idea.</strong> See the following sketch for an intuition.</p><p><img loading=lazy src=./ex-4_0.jpg alt=image></p><ul><li>Compute cumulative sums $q_i$.</li><li>Construct k intervals, each of size $1/k$.</li><li>If some $q_i$ is sandwiched in some interval, separate that interval to two pieces.</li><li>Accordingly label pieces which $p_i$ they belong to.</li><li>Sample a <code>UniformLBitInteger</code> to select a uniformly random interval out of those k intervals.</li><li>If it is separated, Toss a coin by <code>BiasedBit</code> to decide a piece.</li><li>Output the piece&rsquo;s label.</li></ul><p><strong>Algorithm.</strong></p><pre tabindex=0><code>    # input: probabilities P[i]
    # output: cumulative sum of probabilities S[i]
    def cumulativeSum( P[1..k] )
        S = []
        sum = 0
        
        for i in 1..k
            sum += P[i]
            S.append(sum)
        
        return S


    # input: integer k
    # output: k-intervals of size 1/k each
    def kIntervalsConstruction( k )

        # start, end, and separation points, decides a pair of intervals
        # end - start = 1/k
        intervals = [
            [st, end, sep, label]
        ]

        # construct the k intervals
        for i in 1..k
            
            # length of interval is 1/k
            intervals.append(
                [ (i-1)/k, i/k, NULL, NULL ]
            )

        return intervals


    # input: 2d-array of k-intervals, and the cumulative sum S
    # output: None. It modifies the 2d-array to be filled with separators and labels
    def sepPointsFromArray( Inter[1..k, 4], S[1..k] )
        
        # pointer for S
        S_poi = 1

        # for each kth interval
        for i in 1..k

            # if S[S_poi] is contained in the kth interval
            if Inter[i][st] &lt;= S[ S_poi ] &lt;= Inter[i][en]
                
                # set S[S_poi] as the separator
                Inter[i][sep] = S[ S_poi ]

                # consider next index
                S_poi += 1

            # otherwise, leave the separator with NULL

            # in either cases cache S_poi
            # latter case. whole interval is labeled by S_poi
            # former case. first piece is labeled by S_poi and
            #   second piece is labeled by S_poi+1
            Inter[i][label] = S_poi


    # input: k-probabilities P[i]
    # output: k intervals, each of size 1/k, possibly separated to have pairs
    def intervalToPieces( P[1..k] )
        
        # S[i] is cumulative sum up to P[i]
        S = cumulativeSum( P )

        # construct k-intervals of size 1/k each
        intervals = kIntervalsConstruction( k )

        # in-place fill &#34;sep&#34; and &#34;label&#34; cells in intervals
        sepPointsFromArray(intervals, S)

        return intervals


    # input: Probabilities P[i]
    # output: sampled category i
    def sample( P[1..k] )

        # preprocessing is not needed to be called for every sample call
        intervals = intervalToPieces( P )

        # uniform random index of intervals
        randIndex = uniformLBitInteger(lg k)

        # uniform random interval from intervals
        randInterval = intervals[ randIndex ]

        # if it has no separator
        if randInterval[sep] = NULL
            
            # then it belongs to cached label
            return randInterval[label]
        else

        # it has a separator
            
            # compute proportion of separator in ratio to the interval of size 1/k
            prop = (randInterval[sep] - randInterval[st]) / (1/k)

            # toss a coin by a probability proportional to the separator
            if biasedBit(prop)
                
                # if it lands before the separator then we are in a piece labeled by &#34;cached label&#34;
                return randInterval[label]
            else

                # if it lands after the separator then we are in the piece next to one labeled by &#34;cached label&#34;
                return randInterval[label] + 1
</code></pre><p><strong>Correctness.</strong> No probabilistic claim is outside what we proved and illustrated in previous exercises.</p><p><strong>Time Complexity.</strong> Preprocessing consumes $O(k)$, Since all its subroutines take $O(k)$ each. Sampling consumes $O(1)$ since both <code>uniformLBitInteger</code> and <code>biasedBit</code> consume $O(1)$.</p><h3 id=ex.-5 class=unnumbered>Ex. 5<a hidden class=anchor aria-hidden=true href=#ex.-5>#</a></h3><p><strong>Postponed.</strong></p><h3 id=ex.-6 class=unnumbered>Ex. 6<a hidden class=anchor aria-hidden=true href=#ex.-6>#</a></h3><p><strong>Note.</strong> It feels weird we derived a solution better than the requested bound.</p><p><strong>Algorithm</strong></p><pre tabindex=0><code>    def uniformPrime(n)
        do
            # keep sampling uniform numbers in {1, .., 20n}
            rand = uniformRandom(20n)

        # as long as the sampled is not prime
        while not isPrime(rand)

        # only if we found a prime, we return it
        return rand
</code></pre><p><strong>Correctness.</strong> We used the technique of <em>Rejection Sampling</em> which guarantees the prime number output is uniform. The proof idea is very similar to our previous probability proofs.</p><p><strong>Analysis.</strong> From <em>Fact A.2.12</em> (page 226), There are at least $n/\ln n$ primes in $P_n$. So the probability of a successful trial is at least $n/\ln n$. Then the number of trials is at most $\ln n/n$ in expectation by <em>Fact A.3.20</em> (page 233). Observe $\ln n / n \leq \log n / n$. Since we are given <code>isPrime</code> is $\mathcal{O}(\log^7 n)$, The whole algorithm <code>uniformPrime</code> takes at most $\mathcal{O}(\log^8 / n) \subset \mathcal{O}(\log^{10} n)$.</p><h3 id=ex.-7 class=unnumbered>Ex. 7<a hidden class=anchor aria-hidden=true href=#ex.-7>#</a></h3><h4 id=part-i-2 class=unnumbered>Part I<a hidden class=anchor aria-hidden=true href=#part-i-2>#</a></h4><p><img loading=lazy src=./ex-2.7_0.png alt=image></p><p>The probability of sampling from $R$ is $\nfrac{\textit{disk-area}}{\textit{square-area}} = \nfrac{\pi(1)^2}{2*2} \approx \nfrac{22}{7} \cdot \nfrac{1}{4} = \nfrac{22}{28}$.</p><p>It follows the number of iterations is at most $\nfrac{28}{22} = 1 + \nfrac{3}{11} \leq 2$.</p><h4 id=part-ii-2 class=unnumbered>Part II<a hidden class=anchor aria-hidden=true href=#part-ii-2>#</a></h4><p><strong>Partially Solved.</strong></p><p>Seemingly we just need to compute volumes of both $S$ and $R$ but in $20th$ dimension, and follow exactly the same recipe of <em>Part I</em>.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://mostafatouny.github.io/>Mostafa Touny</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>