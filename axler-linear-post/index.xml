<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Axler's Linear Algebra on Mostafa Touny</title><link>https://mostafatouny.github.io/axler-linear-post/</link><description>Recent content in Axler's Linear Algebra on Mostafa Touny</description><generator>Hugo -- 0.136.5</generator><language>en-us</language><lastBuildDate>Sat, 27 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://mostafatouny.github.io/axler-linear-post/index.xml" rel="self" type="application/rss+xml"/><item><title>Ch. 03, Sec. F</title><link>https://mostafatouny.github.io/axler-linear-post/ch03-secf/</link><pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate><guid>https://mostafatouny.github.io/axler-linear-post/ch03-secf/</guid><description>&lt;h2 id="exercises" class="unnumbered">Exercises&lt;/h2>
&lt;h3 id="ex.-01" class="unnumbered">Ex. 01&lt;/h3>
&lt;p>Assume $\varphi$ is not the zero map. Then for some vector $v_0$, $\varphi(v_0) = \lambda_0 \neq 0$. Let $\lambda \in F$ be arbitrary. Then by linearity $\varphi(\lambda \cdot (\lambda_0)^{-1} v_0) = \lambda (\lambda_0)^{-1} \lambda_0 = \lambda$. Hence surjective.&lt;/p></description></item><item><title>Ch. 03, Sec. E</title><link>https://mostafatouny.github.io/axler-linear-post/ch03-sece/</link><pubDate>Mon, 08 Jan 2024 00:00:00 +0000</pubDate><guid>https://mostafatouny.github.io/axler-linear-post/ch03-sece/</guid><description>&lt;h2 id="exercises" class="unnumbered">Exercises&lt;/h2>
&lt;h3 id="ex.-02" class="unnumbered">Ex. 02&lt;/h3>
&lt;p>It follows immediately by &lt;em>dimension of a product&lt;/em> theorem (page 92), As any $dim V_j$ must be upper-bounded by a finite number.&lt;/p></description></item><item><title>Ch. 07, Sec. B</title><link>https://mostafatouny.github.io/axler-linear-post/ch07-secb/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://mostafatouny.github.io/axler-linear-post/ch07-secb/</guid><description>&lt;p>$\newcommand{\ddfrac}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}$&lt;/p>
&lt;h2 id="exercises" class="unnumbered">Exercises&lt;/h2>
&lt;h3 id="ex.-01" class="unnumbered">Ex. 01&lt;/h3>
&lt;p>False. If there is a basis consisting of eigenvectors of $T$, Then $M(T)$ is diagonal. It follows $M(T) M(T)^* = M(T)^* M(T)$, Equivalently $TT^* = T^*T$, So $T$ is self-adjoint.&lt;/p>
&lt;h3 id="ex.-02" class="unnumbered">Ex. 02&lt;/h3>
&lt;p>Assume $F = \mathbb{R}$.&lt;/p>
&lt;p>&lt;strong>Observation.&lt;/strong> $p(x) = x^2 -5x + 6 = (x-2)(x-3)$. $p(T) = T^2 -5T + 6I = (T-2I)(T-3I)$&lt;/p>
&lt;p>The goal is $p(T) = 0$. It suffices to show $p(T)v = 0$ for any vector $v$.&lt;/p></description></item><item><title>Ch. 07, Sec. A</title><link>https://mostafatouny.github.io/axler-linear-post/ch07-seca/</link><pubDate>Sun, 13 Aug 2023 00:00:00 +0000</pubDate><guid>https://mostafatouny.github.io/axler-linear-post/ch07-seca/</guid><description>&lt;p>$\newcommand{\ddfrac}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}$&lt;/p>
&lt;h2 id="exercises">Exercises&lt;/h2>
&lt;h3 id="ex-11">Ex. 11&lt;/h3>
&lt;p>&lt;img loading="lazy" src="./ex-11.jpg" alt="image" />
&lt;/p>
&lt;p>$(\rightarrow)$ Observe $v = v_U + v_{U^\bot}$ and $w = w_U + w_{U^\bot}$. Clearly,
\begin{aligned}
\langle Pv, w \rangle &amp;amp;= \langle v_U, w \rangle \\
&amp;amp;= \langle v_U, w_{U^\bot} \rangle + \langle v_U, w_U \rangle \\
&amp;amp;= 0 + \langle v_U, w_U \rangle \\
\langle v, Pw \rangle &amp;amp;= \langle v_{U^\bot}, w_U \rangle + \langle v_U, w_U \rangle \\
&amp;amp;= 0 + \langle v_U, w_U \rangle
\end{aligned}&lt;/p></description></item></channel></rss>